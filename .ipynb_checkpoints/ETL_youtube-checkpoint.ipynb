{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "import pandas as pd\n",
    "import datetime \n",
    "from pprint import pprint\n",
    "import json\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract CSVs into DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got our data from https://www.kaggle.com/datasnaek/youtube-new. We chose to work with the CSV and JSON files for Canada. CSV was easy to extract, the JSON file required a few additional steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing csv file\n",
    "\n",
    "csv_file = \"Resources/CA_youtube_trending_data.csv\"\n",
    "canada = pd.read_csv(csv_file)\n",
    "canada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing json file\n",
    "\n",
    "json_file = \"Resources/CA_category_id.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json file as 'data'\n",
    "\n",
    "with open(json_file) as file:\n",
    "    data = json.load(file)\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put 'data' into lists\n",
    "\n",
    "category_id = []\n",
    "channel_id = []\n",
    "title = []\n",
    "\n",
    "for item in data[\"items\"]:\n",
    "    category_id.append(item['id'])\n",
    "    channel_id.append(item['snippet']['channelId'])\n",
    "    title.append(item['snippet']['title'])\n",
    "    \n",
    "title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  create dictionary from the lists then to dataframe\n",
    "\n",
    "category_dict = { \"category_id\": category_id,\n",
    "                 \"category_title\":title\n",
    "}\n",
    "\n",
    "category_df = pd.DataFrame(category_dict)\n",
    "category_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the transform section we will clean, amend, and select specific columns and rows that we want to work with. We will also be merging, aggregating, and filtering the dataframes. At the end, we will create a few new tables out of the original two based on the end objective of our project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canada DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns we want to work with from CSV\n",
    "\n",
    "canada_one = canada[[\"video_id\", \"title\", \"publishedAt\", \"channelTitle\", \"categoryId\",\n",
    "                    \"view_count\", \"likes\", \"dislikes\", \"comment_count\", \"thumbnail_link\", \"description\"]]\n",
    "canada_one.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all null values\n",
    "\n",
    "canada_one = canada_one.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns \n",
    "\n",
    "canada_one = canada_one.rename(columns={\"publishedAt\": \"published_at\",\n",
    "                                      \"channelTitle\": \"channel_title\",\n",
    "                                      \"categoryId\": \"category_id\"\n",
    "                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change format of published date column so we can work with it\n",
    "\n",
    "canada_one[\"published_at\"] = pd.to_datetime(canada_one[\"published_at\"])\n",
    "canada_one['published_at'] = canada_one[\"published_at\"].apply(lambda x: x.strftime('%d-%m-%Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouped data on 'video_id' to collect only the latest date's data\n",
    "\n",
    "canada_df = canada_one.groupby('video_id').last()\n",
    "canada_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types\n",
    "\n",
    "canada_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 'category_id' into int64\n",
    "\n",
    "category_df['category_id'] = category_df['category_id'].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm change\n",
    "\n",
    "category_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two dataframes together on 'category_id'\n",
    "\n",
    "merged_df = pd.merge(canada_df , category_df, how = 'inner', on = 'category_id' )\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a grouped dataframe that shows sum of videos, view counts, likes, dislikes, comment counts of each video category\n",
    "\n",
    "\n",
    "data_one = merged_df.groupby(['category_title', 'category_id']).sum()\n",
    "data_one = data_one.rename(columns = {\n",
    "                                                      \"view_count\":\"total_view_count\",\n",
    "                                                      \"likes\": \"total_likes\",\n",
    "                                                      \"dislikes\": \"total_dislikes\",\n",
    "                                                      \"comment_count\": \"total_comment_count\"})\n",
    "data_one = data_one.reset_index()\n",
    "\n",
    "data_two = merged_df.groupby('category_title').sum()\n",
    "data_two = data_two.reset_index()\n",
    "data_two = data_two[[\"category_title\", 'category_id']]\n",
    "data_two = data_two.rename(columns={\"category_id\": \"number_of_videos\"})\n",
    "\n",
    "category_data = pd.merge(data_one, data_two, on=\"category_title\")\n",
    "category_data = category_data.drop(columns='category_title', axis=1)\n",
    "category_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge original video dataframe with category_df\n",
    "\n",
    "merged = pd.merge(canada_one , category_df, how = 'inner', on = 'category_id' )\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a video_category dataframe to serve as junction table\n",
    "\n",
    "video_category = merged[['video_id','category_id']]\n",
    "video_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load DataFrames into SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then load all of our dataframes into postgres sql. We chose to go with SQL because our data is relational, not too large and is structured and we anticipate that the analysis portion to come will require fast analytical queries and joining of some of the tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up connection to sql\n",
    "\n",
    "engine = create_engine(\"postgresql://yingfeng:summer.0@/youtube_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all the tables created in sql\n",
    "\n",
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all the table data\n",
    "\n",
    "category_df.to_sql(name='category_df', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_data.to_sql(name='category_data', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canada_df.to_sql(name='canada_df', con=engine, if_exists='append', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_category.to_sql(name='video_category', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
